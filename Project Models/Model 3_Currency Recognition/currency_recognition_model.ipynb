{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense, BatchNormalization, Activation, Dropout, MaxPooling2D, Input, Reshape\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from keras.utils import plot_model\n",
    "# Define train, test, and validation directories\n",
    "train_dir = r'C:\\Users\\Microsoft\\Money\\dataset\\test'\n",
    "val_dir = r'C:\\Users\\Microsoft\\Money\\dataset\\valid'\n",
    "test_dir = r'C:\\Users\\Microsoft\\Money\\dataset\\test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = sorted([dir_name for dir_name in os.listdir(train_dir)])\n",
    "\n",
    "# Define a smaller image size\n",
    "IMG_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_images_from_folder(folder_path):\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    for class_folder in tqdm(os.listdir(folder_path)):\n",
    "        class_path = os.path.join(folder_path, class_folder)\n",
    "        if os.path.isdir(class_path):\n",
    "            label = class_folder\n",
    "            for image_file in os.listdir(class_path):\n",
    "                image_path = os.path.join(class_path, image_file)\n",
    "                img = Image.open(image_path).convert('RGB').resize((IMG_SIZE, IMG_SIZE))\n",
    "                img_array = np.array(img, dtype=np.uint8)\n",
    "                images.append(img_array)\n",
    "                labels.append(label)\n",
    "    \n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, train_labels  = read_images_from_folder(train_dir)\n",
    "valid_images, valid_labels  = read_images_from_folder(val_dir)\n",
    "test_images, test_labels = read_images_from_folder(test_dir)\n",
    "\n",
    "num_classes = len(np.unique(train_labels))\n",
    "Classes = np.unique(train_labels)\n",
    "print(f\"Classes: {Classes}\")\n",
    "print(f\"Number of classes: {num_classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_statistics(images, dataset_name):\n",
    "    print(f\"Dataset: {dataset_name}\")\n",
    "    print(f\"Number of images: {len(images)}\")\n",
    "    \n",
    "    # Calculate statistics about image shapes\n",
    "    print(f\"Image shapes: {images.shape}\")\n",
    "    print(\"------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "image_statistics(train_images, \"Train\")\n",
    "image_statistics(valid_images, \"Validation\")\n",
    "image_statistics(test_images, \"Test\")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "pd.DataFrame(train_labels).value_counts().sort_index().plot(kind='bar')\n",
    "plt.title('Training Data Class Distribution')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 9 random indices\n",
    "sample_indices = random.sample(range(len(train_images)), 9)\n",
    "\n",
    "# Create a 3x3 grid of subplots for plotting the images\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.suptitle(\"Some Sample Images\", fontsize=16)\n",
    "\n",
    "for i, idx in enumerate(sample_indices):\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(train_images[idx])  # Assuming images are already in the appropriate format\n",
    "    plt.title(f\"Label: {train_labels[idx]}\")\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
    "valid_labels_encoded = label_encoder.transform(valid_labels)\n",
    "test_labels_encoded = label_encoder.transform(test_labels)\n",
    "\n",
    "num_classes = len(label_encoder.classes_)\n",
    "\n",
    "train_labels_one_hot = to_categorical(train_labels_encoded, num_classes=num_classes)\n",
    "valid_labels_one_hot = to_categorical(valid_labels_encoded, num_classes=num_classes)\n",
    "test_labels_one_hot = to_categorical(test_labels_encoded, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):   \n",
    "    # Access the training history\n",
    "    train_loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    train_acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "\n",
    "    # Create subplots for loss and accuracy\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    # Plot training and validation loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_loss, label='Training Loss')\n",
    "    plt.plot(val_loss, label='Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Training and Validation Loss')\n",
    "    # Plot training and validation accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(train_acc, label='Training Accuracy')\n",
    "    plt.plot(val_acc, label='Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_class(model, test_images, test_labels, num_images_to_plot=12, num_columns=4):\n",
    "    # Decode one-hot encoded labels\n",
    "    test_labels = np.argmax(test_labels_one_hot, axis=1)\n",
    "    \n",
    "    # Choose random indices for testing\n",
    "    random_indices = np.random.choice(len(test_images), size=num_images_to_plot, replace=False)\n",
    "\n",
    "    # Calculate the number of rows needed based on the number of images and columns\n",
    "    num_rows = int(np.ceil(len(random_indices) / num_columns))\n",
    "\n",
    "    # Create a subplot with the specified number of rows and columns\n",
    "    fig, axes = plt.subplots(num_rows, num_columns, figsize=(15, 3*num_rows))\n",
    "\n",
    "    # Loop through the selected indices for prediction and plotting\n",
    "    for i, ax in zip(random_indices, axes.flatten()):\n",
    "        # Get the image and label\n",
    "        image = test_images[i]\n",
    "        label = test_labels[i]\n",
    "\n",
    "        # Reshape the image to match the input shape expected by the model\n",
    "        image = np.expand_dims(image, axis=0)\n",
    "\n",
    "        # Predict the image using the loaded model\n",
    "        prediction = model.predict(image)\n",
    "\n",
    "        # Get the predicted label\n",
    "        predicted_label = np.argmax(prediction)\n",
    "\n",
    "        # Plot the image\n",
    "        ax.imshow(image.squeeze())  # Squeeze to remove the singleton dimension\n",
    "        ax.set_title(f\"Actual Label: {label}\\n Predicted Label: {predicted_label}\")\n",
    "\n",
    "    # Adjust layout for better spacing\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of epochs\n",
    "NUM_CLASSES = num_classes\n",
    "num_epochs = 200\n",
    "batch_size = 32\n",
    "\n",
    "# Early stopping to prevent overfitting\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=30, verbose=2, restore_best_weights=True)\n",
    "\n",
    "# Build the deep learning model\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# model.summary()\n",
    "#plot_model(model, show_shapes=True, show_layer_names=True)\n",
    "\n",
    "# Start training the model\n",
    "history = model.fit(\n",
    "    train_images,\n",
    "    train_labels_one_hot,\n",
    "    epochs=num_epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=(valid_images, valid_labels_one_hot),\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "plot_history(history)\n",
    "model.evaluate(test_images, test_labels_one_hot)\n",
    "predict_class(model, test_images, test_labels_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "model.save('model.h5')\n",
    "from tensorflow.keras.applications import MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use MobileNetV2 as an example of a lighter architecture\n",
    "base_model = MobileNetV2(input_shape=(IMG_SIZE, IMG_SIZE, 3), include_top=False, weights='imagenet')\n",
    "\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.evaluate(test_images, test_labels_one_hot)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
